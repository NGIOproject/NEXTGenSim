/*
 * Copyright 2007 Francesc Guim Bernat & Barcelona Supercomputing Centre (fguim@pcmas.ac.upc.edu)
 * Copyright 2019 Daniel Rivas & Barcelona Supercomputing Centre (daniel.rivas@bsc.es)
 * Copyright 2015-2019 NEXTGenIO Project [EC H2020 Project ID: 671951] (www.nextgenio.eu)
 *
 * This file is part of NEXTGenSim.
 *
 * NEXTGenSim is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * NEXTGenSim is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * 
 * You should have received a copy of the GNU General Public License
 * along with NEXTGenSim.  If not, see <https://www.gnu.org/licenses/>.
 */
/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */

/* 
 * File:   otf2trace.cpp
 * Author: nick
 * 
 * Created on 22 November 2017, 13:39
 */

#include <utils/otf2trace.h>

namespace Utils {

    otf2trace::otf2trace() {
    }

    otf2trace::otf2trace(const otf2trace& orig) {
    }

    otf2trace::~otf2trace() {
    }

    std::chrono::high_resolution_clock::time_point get_time(void) {
        static std::size_t count = 0;
        //        std::cout << "Count: " << count << std::endl;
        /*
         * Need to understand what a "time point" and how it relates to duration.
         * From cpprefernce.com
         *
         * Duration: A duration consists of a span of time, defined as some number of ticks of some time unit.
         * For example, "42 seconds" could be represented by a duration consisting of 42 ticks of a 1-second time unit.
         *
         * Time Point: A time point is a duration of time that has passed since the epoch of specific clock
         *
         * So, we convert count to a duration, but do not specify the time unit
         */

        std::chrono::high_resolution_clock::duration dur = std::chrono::high_resolution_clock::duration(count++);
        std::chrono::high_resolution_clock::time_point a = std::chrono::high_resolution_clock::time_point(dur);

        // std::chrono::high_resolution_clock::time_point a =  std::chrono::high_resolution_clock::time_point( std::chrono::high_resolution_clock:: duration(count++));
        std::cout << a.time_since_epoch().count() << std::endl;
        std::cout << std::chrono::duration_cast<std::chrono::nanoseconds>(dur).count() << std::endl;
        // std::cout << "a.per.num = " << num << std::endl;

        return a;

        // std::chrono::high_resolution_clock::time_point( std::chrono::high_resolution_clock::duration(count++) );
    }

    void otf2trace::setLog(Log* log) {
        this->log = log;
        log->debug("Log set", 1);
        log->debug("Output filename for otf2 set to " + this->tracename, 1);
        log->debug("Output directory for otf2 set to " + this->tracedir, 1);
    }

    void otf2trace::jobStart(int job_id, deque<ResourceBucket*>& allocations, bool do_io) {
        /*
         * Job Start
         * For each node used, generate a region for this job.
         * Pick up the location by indexing the "locations" vector.
         */
        log->debug("OTF2 jobStart for job:" + to_string(job_id) + ".", 1);


        /*
         * For each member of allocations (each bucket), define a "region" and create a member in the job_regions array
         * The member in the array holds the region (to use at job finish), the job_id (for indexing) and the nodeid (to ensure the leave event happens on the same "location" the enter did)
         * The "location" index is identical to the nodeid index used in the simulator, but this is shaky as we assume a single partition etc.
         */
        for (deque<ResourceBucket*>::iterator it = allocations.begin(); it != allocations.end(); ++it) {
            ResourceBucket* bucket = *it;


            /*
             * To avoid the cryptic error about locations (ie when you have a location that contains no regions)
             * Just add the locations as and when they are first used. OTF2 makes this unnecessarily complex.
             * And now we cannot assume that locations[jr.nodeid] was generated by nodeid.
             * int nodeloc[numNodes];
             * nodeloc[X] holds index in locations of location for nodeID x.
             */
            if (locations_used[bucket->getID()] == false) {
                locations_used[bucket->getID()] = true;
                otf2::definition::location l(bucket->getID(), strings[3], location_groups[bucket->getID()], otf2::definition::location::location_type::cpu_thread);
                node_locations[bucket->getID()] = locations.size();
                locations.push_back(l);
                //                cout << "location diag   NODE: " << to_string(bucket->getID()) << " INDEX: " << to_string(locations.size()-1) << endl;
                (*p_ar) << l;
            }

            log->debug("OTF2 Locationally correct: " + to_string(job_id) + ".", 1);
            /*
             * Generate the region for this bucket, and push that to the archive.
             * Note that regioncount is actually a user defined tag that we don't desperately care about, except that it must be unique.
             */
            /*
             * A little hackery, but essentially, if do_io is false, it's in the middle of the workflow and we can just have a job with no IO.
             */

            struct jobregion jr;
            jr.jobid = (int) job_id;
            jr.nodeid = bucket->getID();

                
            if (do_io == true) {
                otf2::definition::region region(regioncount++, strings[10 + job_id], strings[5], strings[6], otf2::definition::region::role_type::file_io, otf2::definition::region::paradigm_type::user, otf2::definition::region::flags_type::none, strings[7], 0, 0);
                log->debug("OTF2 Region okay " + to_string(job_id) + ".", 1);
                (*p_ar) << region; // You can push back a region directly to an archive.

                log->debug("OTF2 BUCKET iterator:" + to_string(job_id) + ".", 1);
                /*
                 * Create a struct to hold information about this job region, the job ID, the region handle and the bucket ID.
                 * Then, place this into the array of all job region structs, for later reference.
                 */
                jr.region = region;
            

            } else {
                otf2::definition::region region(regioncount++, strings[10 + job_id], strings[5], strings[6], otf2::definition::region::role_type::function, otf2::definition::region::paradigm_type::user, otf2::definition::region::flags_type::none, strings[7], 0, 0);
                log->debug("OTF2 Region okay " + to_string(job_id) + ".", 1);
                (*p_ar) << region; // You can push back a region directly to an archive.

                log->debug("OTF2 BUCKET iterator:" + to_string(job_id) + ".", 1);
                /*
                 * Create a struct to hold information about this job region, the job ID, the region handle and the bucket ID.
                 * Then, place this into the array of all job region structs, for later reference.
                 */
                jr.region = region;

            }
            
            job_regions.push_back(jr);

            //            log->debug("OTF2 Region okay " + to_string(job_id) + ".", 1);
            //            (*p_ar) << region; // You can push back a region directly to an archive.
            //
            //            log->debug("OTF2 BUCKET iterator:" + to_string(job_id) + ".", 1);
            //            /*
            //             * Create a struct to hold information about this job region, the job ID, the region handle and the bucket ID.
            //             * Then, place this into the array of all job region structs, for later reference.
            //             */
            //            struct jobregion jr;
            //            jr.jobid = (int) job_id;
            //            jr.region = region;
            //            jr.nodeid = bucket->getID();
            //            //            cout << "JOBID: " << job_id <<  "BUCKETID: " << jr.nodeid << endl;
            //            job_regions.push_back(jr);
            //

            /*
             * Perform the usual maneuver to convert a duration to a time_point and later to a thing suitable for an enter or leave event.
             */
            std::chrono::high_resolution_clock::duration dur = std::chrono::high_resolution_clock::duration((int) bucket->getStartTime());
            std::chrono::high_resolution_clock::time_point a = std::chrono::high_resolution_clock::time_point(dur);
            //            cout << "TS   " << (int) bucket->getStartTime() << endl;
            //            (*p_ar)(locations[jr.nodeid]) << otf2::event::enter(otf2::chrono::convert_time_point(get_time()), region);




            log->debug("OTF2 JobSta  (" + to_string(job_id) + ") at " + to_string(bucket->getStartTime()) + " on Node " + to_string(jr.nodeid), 6);
            (*p_ar)(locations[node_locations[(int) jr.nodeid]]) << otf2::event::enter(otf2::chrono::convert_time_point(a), jr.region);

            /*
             * It's one LOCATION per node, but each LOCATION can support multiple REGIONS.
             */

        }

    }

    void otf2trace::jobEnd(int job_id, deque<ResourceBucket*>& allocations, bool do_io) {

        /*
         * The job has ended.
         * Ideally, we'd delete all the lingering the regions, BUT, you might get racy behaviour.
         * NOTE: Never use the bucket endtime for determining the finishing times of jobs.
         * The bucket end time is set to be the starttime+runtime
         * The correct time to use is _now_, ie globalTime
         * The do_io flag can be ignored for now. OTF2 is weird.
         */


        // Loop over all the job regions and find the ones which have the desired job id.
        for (uint i = 0; i < job_regions.size(); ++i) {
            if (job_regions[i].jobid == job_id) {
                std::chrono::high_resolution_clock::duration dur = std::chrono::high_resolution_clock::duration((int) rsp->globalTime);
                log->debug("OTF2 JobEnd  (" + to_string(job_id) + ") at " + itos(rsp->globalTime) + " on Node " + to_string(job_regions[i].nodeid), 6);
                std::chrono::high_resolution_clock::time_point a = std::chrono::high_resolution_clock::time_point(dur);
                (*p_ar)(locations[node_locations[job_regions[i].nodeid]]) << otf2::event::leave(otf2::chrono::convert_time_point(a), job_regions[i].region);

            }
        }



    }

    void otf2trace::init(std::string tracename_in, std::string tracedir_in, Partition* p, int number_of_jobs) {
        this->tracename = tracename_in;
        this->tracedir = tracedir_in;
        this->rsp = p->getSchedulingPolicy();
        this->numNodes = p->getNumNodes();
        this->numJobs = (unsigned int) number_of_jobs;

        path tracepath(tracedir);


        /*
         * This is the long method whereby we do not clobber anything other than the OTF2 trace in the tracedir
         * It would not be needed if the higher level code clobbered the whole tracedir (remove_all(tracedir)) on start
         * The advantage of the long method is that products from earlier runs e.g. when running a comparison, are no clobbered
         * Nor are runs using other filenames, again might be useful in comparisons.
         */

        if (exists(tracepath) && is_directory(tracepath)) {
            log->debug("tracepath: " + tracepath.native() + " exists and is a directory.", 1);
        }

        /*
         * OTF2 creates many many files. You get (in tracedir)
         * tracename.otf2
         * tracename.def
         * tracename.marker
         * tracename/ as a dir containing many more files
         */
        path tracename_otf2 = path(tracedir + "/" + tracename + ".otf2");
        if (exists(tracename_otf2)) {
            bool res = remove(tracename_otf2);
            if (res) {
                log->debug("tracename: " + tracename_otf2.native() + " was removed.", 1);
            } else {
                log->debug("tracename: " + tracename_otf2.native() + " was not removed, there was an error.", 1);
            }
        } else {
            log->debug("tracename: " + tracename_otf2.native() + " does not exist.", 1);
        }

        path tracename_marker = path(tracedir + "/" + tracename + ".marker");
        if (exists(tracename_marker)) {
            bool res = remove(tracename_marker);
            if (res) {
                log->debug("tracename: " + tracename_marker.native() + " was removed.", 1);
            } else {
                log->debug("tracename: " + tracename_marker.native() + " was not removed, there was an error.", 1);
            }
        } else {
            log->debug("tracename: " + tracename_marker.native() + " does not exist.", 1);
        }

        path tracename_def = path(tracedir + "/" + tracename + ".def");
        if (exists(tracename_def)) {
            bool res = remove(tracename_def);
            if (res) {
                log->debug("tracename: " + tracename_def.native() + " was removed.", 1);
            } else {
                log->debug("tracename: " + tracename_def.native() + " was not removed, there was an error.", 1);
            }
        } else {
            log->debug("tracename: " + tracename_def.native() + " does not exist.", 1);
        }

        path tracename_dir = path(tracedir + "/" + tracename);
        if (exists(tracename_dir) && is_directory(tracename_dir)) {
            bool res = remove_all(tracename_dir);
            if (res) {
                log->debug("tracename: " + tracename_dir.native() + " was removed.", 1);
            } else {
                log->debug("tracename: " + tracename_dir.native() + " was not removed, there was an error.", 1);
            }
        } else {
            log->debug("tracename: " + tracename_dir.native() + " does not exist.", 1);
        }



        /*
         * This function is not safe as it returns successfully even if the underlying library errors due to existing file.
         * It requires protecting by ensuring that if the file(s) already exists, it gets clobbered first.
         */
        static otf2::writer::archive ar(this->tracedir, this->tracename);
        p_ar = &ar;

        /*
         * OTF2 requires us to have this. Essentially, you have to pass it something to do after it flushes
         * things from it's internal memory buffer to the file.
         */
        ar.set_post_flush_callback([]() {
            return otf2::chrono::convert_time_point(get_time()); });
        //
        log->debug("callback set", 4);

        /*
         * String definitions go in here.
         * They are free form and don't have any special meaning.
         */
        strings.add_definition({0, "MyMachine"});
        strings.add_definition({1, "nodeYY"});
        strings.add_definition({2, "Master Process"});
        strings.add_definition({3, "Node"});
        strings.add_definition({4, "MyFunction"});
        strings.add_definition({5, "Alternative function name (e.g. mangled one)"});
        strings.add_definition({6, "Computes something"});
        strings.add_definition({7, ""});
        strings.add_definition({8, "MACHINE"});
        strings.add_definition({9, "MyNEWFunction"});
        strings.add_definition({10, "nodeXX"});

        for (unsigned int i = 0; i < numJobs; ++i) {
            strings.add_definition({11 + i, "Job " + to_string(i + 1)});
        }


        ar << strings;
        log->debug("Pushed strings to archive", 1);


        /*
         * Define root node (the machine) and push directly
         * This node won't do any work so we don't store in "nodes".
         */
        otf2::definition::system_tree_node root_node(0, strings[8], strings[1]);
        ar << root_node;
        log->debug("Pushed root_node to archive", 1);


        /*
         * We ignore the root_node as a node
         * It will never have any work assigned
         * BUT, we offset node references to account for it
         */
        for (uint i = 0; i < numNodes; ++i) {
            otf2::definition::system_tree_node sub_node(i + 1, strings[0], strings[10], root_node);
            nodes.push_back(sub_node);
            ar << sub_node;
        }
        log->debug("Pushed back sub_nodes & pushed to archive");


        //        log->debug("size of nodes is " + to_string(nodes.size()), 1);
        //        for (uint i = 0; i < nodes.size(); ++i) {
        //            ar << nodes[i];
        //        }

        otf2::definition::clock_properties ac = otf2::definition::clock_properties(otf2::chrono::ticks(1), otf2::chrono::ticks(0), otf2::chrono::ticks(1));
        //        otf2::definition::clock_properties ac = otf2::definition::clock_properties(otf2::chrono::ticks(1), otf2::chrono::ticks(0));
        ar << ac;
        log->debug("Pushed clock to archive", 1);
        locations_used.resize(numNodes);
        node_locations.resize(numNodes);

        /*
         * For each NODE, generate a location_group AND a location
         * Push them to the file.
         */
        for (uint i = 0; i < numNodes; ++i) {
            otf2::definition::location_group lg(i, strings[2], otf2::definition::location_group::location_group_type::process, nodes[i]);
            location_groups.push_back(lg);
            ar << lg;
        }


    }

    void otf2trace::simFinished(uint32_t finTime) {
        otf2::definition::clock_properties ac = otf2::definition::clock_properties(otf2::chrono::ticks(1), otf2::chrono::ticks(0), otf2::chrono::ticks(finTime + 60));
        (*p_ar) << ac;
        log->debug("Pushed clock to archive at simFinished", 1);
    }

    void otf2trace::jobBeginCompute(int job_id) {

        // Start by stopping the IO phase
        // Then create the region for the compute phase
        // Push it and update the job_regions table
        // Finally just write and enter event for this new region

        for (uint i = 0; i < job_regions.size(); ++i) {
            if (job_regions[i].jobid == job_id) {
                std::chrono::high_resolution_clock::duration dur = std::chrono::high_resolution_clock::duration((int) rsp->globalTime);
                log->debug("OTF2 JobBeginCompute  (" + to_string(job_id) + ") at " + itos(rsp->globalTime) + " on Node " + to_string(job_regions[i].nodeid), 6);
                std::chrono::high_resolution_clock::time_point a = std::chrono::high_resolution_clock::time_point(dur);
                (*p_ar)(locations[node_locations[job_regions[i].nodeid]]) << otf2::event::leave(otf2::chrono::convert_time_point(a), job_regions[i].region);
                otf2::definition::region region(regioncount++, strings[10 + job_id], strings[5], strings[6], otf2::definition::region::role_type::function, otf2::definition::region::paradigm_type::user, otf2::definition::region::flags_type::none, strings[7], 0, 0);
                (*p_ar) << region; // You can push back a region directly to an archive.
                struct jobregion jr;
                jr.jobid = job_id;
                jr.region = region;
                jr.nodeid = job_regions[i].nodeid;
                job_regions[i] = jr;
                (*p_ar)(locations[node_locations[job_regions[i].nodeid]]) << otf2::event::enter(otf2::chrono::convert_time_point(a), region);
            }
        }


    }

    void otf2trace::jobEndCompute(int job_id) {

        for (uint i = 0; i < job_regions.size(); ++i) {
            if (job_regions[i].jobid == job_id) {
                std::chrono::high_resolution_clock::duration dur = std::chrono::high_resolution_clock::duration((int) rsp->globalTime);
                log->debug("OTF2 JobEndCompute  (" + to_string(job_id) + ") at " + itos(rsp->globalTime) + " on Node " + to_string(job_regions[i].nodeid), 6);
                std::chrono::high_resolution_clock::time_point a = std::chrono::high_resolution_clock::time_point(dur);
                (*p_ar)(locations[node_locations[job_regions[i].nodeid]]) << otf2::event::leave(otf2::chrono::convert_time_point(a), job_regions[i].region);
                otf2::definition::region region(regioncount++, strings[10 + job_id], strings[5], strings[6], otf2::definition::region::role_type::file_io, otf2::definition::region::paradigm_type::user, otf2::definition::region::flags_type::none, strings[7], 0, 0);
                (*p_ar) << region; // You can push back a region directly to an archive.
                struct jobregion jr;
                jr.jobid = job_id;
                jr.region = region;
                jr.nodeid = job_regions[i].nodeid;
                job_regions[i] = jr;
                (*p_ar)(locations[node_locations[job_regions[i].nodeid]]) << otf2::event::enter(otf2::chrono::convert_time_point(a), region);
            }
        }

    }

}